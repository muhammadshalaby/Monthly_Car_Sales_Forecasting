{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8ed43b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\")\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True, figsize=(11, 5))\n",
    "plt.rc(\"axes\", labelweight=\"bold\", labelsize=\"large\", titleweight=\"bold\", titlesize=16, titlepad=10)\n",
    "plot_params = dict(color=\"0.75\", style=\".-\", markeredgecolor=\"0.25\", markerfacecolor=\"0.25\", legend=False)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5ce1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train test split function\n",
    "def train_test_datasets(df, x_len=12, y_len=1, test_loops=12):\n",
    "    D = df.values\n",
    "    rows, periods = D.shape\n",
    "    \n",
    "    # Training set creation\n",
    "    loops = periods + 1 - x_len - y_len\n",
    "    train = []\n",
    "    for col in range(loops):\n",
    "        train.append(D[:, col:col+x_len+y_len])\n",
    "    train = np.vstack(train)\n",
    "    X_train, y_train = np.split(train, [-y_len], axis=1)\n",
    "\n",
    "    # Test set creation\n",
    "    if test_loops > 0:\n",
    "        X_train, X_test = np.split(X_train, [-rows*test_loops], axis=0)\n",
    "        y_train, y_test = np.split(y_train, [-rows*test_loops], axis=0)\n",
    "    else: # No test set: X_test is used to generate the future forecast\n",
    "        X_test = D[:, -x_len:]     \n",
    "        y_test = np.full((X_test.shape[0], y_len), np.nan) #Dummy value\n",
    "    \n",
    "    # Formatting required for scikit-learn\n",
    "    if y_len == 1: \n",
    "        y_train = y_train.ravel()\n",
    "        y_test = y_test.ravel()  \n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# define score metric function\n",
    "def kpi(y_train, y_train_pred, y_test, y_test_pred, name=''):\n",
    "    df = pd.DataFrame(columns = ['MAE','RMSE', 'Bias', 'MAE_pct', 'RMSE_pct', 'r2_score'], index=['Train','Test'])\n",
    "    df.index.name = name\n",
    "    df.loc['Train','MAE_pct'] = 100*np.mean(abs(y_train - y_train_pred))/np.mean(y_train)\n",
    "    df.loc['Train','RMSE_pct'] = 100*np.sqrt(np.mean((y_train - y_train_pred)**2))/np.mean(y_train)\n",
    "    df.loc['Train','Bias'] = 100*np.mean((y_train - y_train_pred))/np.mean(y_train)\n",
    "    df.loc['Train','r2_score'] =  r2_score(y_train, y_train_pred)\n",
    "    df.loc['Train','MAE'] = mean_absolute_error(y_train, y_train_pred)\n",
    "    df.loc['Train','RMSE'] = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "    df.loc['Test','MAE_pct'] = 100*np.mean(abs(y_test - y_test_pred))/np.mean(y_test) \n",
    "    df.loc['Test','RMSE_pct'] = 100*np.sqrt(np.mean((y_test - y_test_pred)**2))/np.mean(y_test)\n",
    "    df.loc['Test','Bias'] = 100*np.mean((y_test - y_test_pred))/np.mean(y_test)\n",
    "    df.loc['Test','r2_score'] =  r2_score(y_test, y_test_pred)\n",
    "    df.loc['Test','MAE'] = mean_absolute_error(y_test, y_test_pred)\n",
    "    df.loc['Test','RMSE'] = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "    df = df.astype(float).round(2) #Round number for display\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "d9b92aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Make</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Smart</td>\n",
       "      <td>6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Dacia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>Maserati</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month      Make  Quantity  Pct\n",
       "3947  2016      1     Smart         6  0.1\n",
       "3948  2016      1      Fiat         5  0.0\n",
       "3949  2016      1      Jeep         4  0.0\n",
       "3950  2016      1     Dacia         1  0.0\n",
       "3951  2016      1  Maserati         1  0.0"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('norway_new_car_sales_by_make.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "052ab83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Period'] = data.Year.astype(str) + '-' + data.Month.astype(str).str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "63b6670a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Make</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Pct</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>2884</td>\n",
       "      <td>22.7</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>2521</td>\n",
       "      <td>19.9</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>Peugeot</td>\n",
       "      <td>1029</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>Ford</td>\n",
       "      <td>870</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>Volvo</td>\n",
       "      <td>693</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month        Make  Quantity   Pct   Period\n",
       "0  2007      1      Toyota      2884  22.7  2007-01\n",
       "1  2007      1  Volkswagen      2521  19.9  2007-01\n",
       "2  2007      1     Peugeot      1029   8.1  2007-01\n",
       "3  2007      1        Ford       870   6.9  2007-01\n",
       "4  2007      1       Volvo       693   5.5  2007-01"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "859b8f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year         0\n",
       "Month        0\n",
       "Make        10\n",
       "Quantity     0\n",
       "Pct          0\n",
       "Period       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "0d189ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Make</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Pct</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2007</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2007-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2009</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month Make  Quantity  Pct   Period\n",
       "37    2007      1  NaN         1  0.0  2007-01\n",
       "112   2007      3  NaN         1  0.0  2007-03\n",
       "265   2007      7  NaN         1  0.0  2007-07\n",
       "419   2007     11  NaN         1  0.0  2007-11\n",
       "1256  2009      9  NaN         4  0.0  2009-09\n",
       "1294  2009     10  NaN         4  0.0  2009-10\n",
       "2399  2012      4  NaN         1  0.0  2012-04\n",
       "2478  2012      6  NaN         1  0.0  2012-06\n",
       "2517  2012      7  NaN         1  0.0  2012-07\n",
       "3013  2013      9  NaN         1  0.0  2013-09"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Make.isnull()] # There is months with out cars sales we will fill 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "769f046a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Period</th>\n",
       "      <th>2007-01</th>\n",
       "      <th>2007-02</th>\n",
       "      <th>2007-03</th>\n",
       "      <th>2007-04</th>\n",
       "      <th>2007-05</th>\n",
       "      <th>2007-06</th>\n",
       "      <th>2007-07</th>\n",
       "      <th>2007-08</th>\n",
       "      <th>2007-09</th>\n",
       "      <th>2007-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2015-04</th>\n",
       "      <th>2015-05</th>\n",
       "      <th>2015-06</th>\n",
       "      <th>2015-07</th>\n",
       "      <th>2015-08</th>\n",
       "      <th>2015-09</th>\n",
       "      <th>2015-10</th>\n",
       "      <th>2015-11</th>\n",
       "      <th>2015-12</th>\n",
       "      <th>2016-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alfa Romeo</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aston Martin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>599</td>\n",
       "      <td>498</td>\n",
       "      <td>682</td>\n",
       "      <td>556</td>\n",
       "      <td>630</td>\n",
       "      <td>498</td>\n",
       "      <td>562</td>\n",
       "      <td>590</td>\n",
       "      <td>393</td>\n",
       "      <td>554</td>\n",
       "      <td>...</td>\n",
       "      <td>665</td>\n",
       "      <td>585</td>\n",
       "      <td>640</td>\n",
       "      <td>754</td>\n",
       "      <td>541</td>\n",
       "      <td>494</td>\n",
       "      <td>549</td>\n",
       "      <td>592</td>\n",
       "      <td>496</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>352</td>\n",
       "      <td>335</td>\n",
       "      <td>365</td>\n",
       "      <td>360</td>\n",
       "      <td>431</td>\n",
       "      <td>477</td>\n",
       "      <td>403</td>\n",
       "      <td>348</td>\n",
       "      <td>271</td>\n",
       "      <td>562</td>\n",
       "      <td>...</td>\n",
       "      <td>733</td>\n",
       "      <td>693</td>\n",
       "      <td>849</td>\n",
       "      <td>617</td>\n",
       "      <td>860</td>\n",
       "      <td>777</td>\n",
       "      <td>1010</td>\n",
       "      <td>934</td>\n",
       "      <td>1024</td>\n",
       "      <td>1089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Period        2007-01  2007-02  2007-03  2007-04  2007-05  2007-06  2007-07  \\\n",
       "Make                                                                          \n",
       "Alfa Romeo         16        9       21       20       17       21       14   \n",
       "Aston Martin        0        0        1        0        4        3        3   \n",
       "Audi              599      498      682      556      630      498      562   \n",
       "BMW               352      335      365      360      431      477      403   \n",
       "Bentley             0        0        0        0        0        1        0   \n",
       "\n",
       "Period        2007-08  2007-09  2007-10  ...  2015-04  2015-05  2015-06  \\\n",
       "Make                                     ...                              \n",
       "Alfa Romeo         12       15       10  ...        3        3        3   \n",
       "Aston Martin        0        0        0  ...        2        2        0   \n",
       "Audi              590      393      554  ...      665      585      640   \n",
       "BMW               348      271      562  ...      733      693      849   \n",
       "Bentley             0        0        0  ...        0        0        0   \n",
       "\n",
       "Period        2015-07  2015-08  2015-09  2015-10  2015-11  2015-12  2016-01  \n",
       "Make                                                                         \n",
       "Alfa Romeo          9        4        5        0        3        3        0  \n",
       "Aston Martin        0        0        0        0        0        0        0  \n",
       "Audi              754      541      494      549      592      496      559  \n",
       "BMW               617      860      777     1010      934     1024     1089  \n",
       "Bentley             0        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.pivot_table(data=data, values='Quantity', index='Make', columns='Period', aggfunc='sum', fill_value=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "77f37ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 65 entries, Alfa Romeo to Westfield\n",
      "Columns: 109 entries, 2007-01 to 2016-01\n",
      "dtypes: int64(109)\n",
      "memory usage: 55.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "1e5ec998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 109)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f67cb",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "cae68254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "Regression                                                 \n",
      "Train       29.50  73.02  -0.0    17.91     44.32      0.95\n",
      "Test        33.56  80.90   0.9    17.32     41.75      0.95\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression as first model to compare\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "reg = Pipeline([('scaler', MinMaxScaler()), ('LinearRegression', LinearRegression())]) # Create a linear regression object\n",
    "\n",
    "reg.fit(X_train, y_train) # Fit it to the training data\n",
    "\n",
    "# Create two predictions for the training and test sets\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d456122",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5ea37056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "Forest                                                 \n",
      "Train   11.23  28.60 -0.14     6.67     16.99      0.99\n",
      "Test    35.00  89.76  1.97    17.43     44.69      0.95\n"
     ]
    }
   ],
   "source": [
    "# use Random Forest with default parameters\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "forest = Pipeline([('scaler', MinMaxScaler()), ('Forest', RandomForestRegressor())])\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = forest.predict(X_train) \n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "03cfe587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 400 candidates, totalling 2400 fits\n",
      "Tuned Forest Parameters: {'Forestb__n_estimators': 100, 'Forestb__min_samples_split': 7, 'Forestb__min_samples_leaf': 6, 'Forestb__max_samples': 0.5, 'Forestb__max_features': 0.4, 'Forestb__max_depth': 19, 'Forestb__bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "pipe_grid = Pipeline([('scaler', MinMaxScaler()), ('Forestb', RandomForestRegressor(n_jobs=1))])\n",
    "\n",
    "param_dist = {'Forestb__n_estimators': list(range(100, 500, 100)),\n",
    "              'Forestb__max_depth': list(range(1, 20)) + [None],\n",
    "              'Forestb__min_samples_split': range(2, 20),\n",
    "              'Forestb__min_samples_leaf': range(1, 20),\n",
    "              'Forestb__max_features': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1] + ['auto'],\n",
    "              'Forestb__bootstrap': [True],\n",
    "              'Forestb__max_samples': [.1, .2, .3, .4, .5, .6, .7, .8, .9, 1]}\n",
    "\n",
    "forest_cv = RandomizedSearchCV(pipe_grid, param_dist, cv=6, n_jobs=-1, verbose=1, n_iter=400)\n",
    "\n",
    "forest_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Tuned Forest Parameters:', forest_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5031f7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1350 candidates, totalling 6750 fits\n",
      "Tuned Forest Parameters: {'Forestf__bootstrap': True, 'Forestf__max_depth': 19, 'Forestf__max_features': 0.4, 'Forestf__max_samples': 0.5, 'Forestf__min_samples_leaf': 5, 'Forestf__min_samples_split': 5, 'Forestf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "pipe_grid_f = Pipeline([('scaler', MinMaxScaler()), ('Forestf', RandomForestRegressor(n_jobs=1))])\n",
    "\n",
    "param_dist_f = {'Forestf__n_estimators': [100],\n",
    "                'Forestf__max_depth': list(range(17, 22)) + [None],\n",
    "                'Forestf__min_samples_split': range(5, 10),\n",
    "                'Forestf__min_samples_leaf': range(4, 9),\n",
    "                'Forestf__max_features': [.35, .4, .45],\n",
    "                'Forestf__bootstrap': [True],\n",
    "                'Forestf__max_samples': [.45, .5, .55]}\n",
    "\n",
    "forest_cv_f = GridSearchCV(pipe_grid_f, param_dist_f, n_jobs=-1, verbose=1)\n",
    "\n",
    "forest_cv_f.fit(X_train, y_train)\n",
    "\n",
    "print('Tuned Forest Parameters:', forest_cv_f.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "52b2f22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "forest_final                                                 \n",
      "Train         23.53  60.29 -0.07    14.42     36.96      0.97\n",
      "Test          34.27  94.47  1.89    18.19     50.14      0.94\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=20)\n",
    "\n",
    "forest_final = Pipeline([('scaler', MinMaxScaler()), ('ForestFinal', RandomForestRegressor(n_estimators=100, \n",
    "                                                                                           min_samples_split=5, \n",
    "                                                                                           min_samples_leaf=5, \n",
    "                                                                                           max_samples=0.5, \n",
    "                                                                                           max_features=0.4, \n",
    "                                                                                           max_depth=19, \n",
    "                                                                                           bootstrap=True))])\n",
    "\n",
    "forest_final.fit(X_train, y_train)  \n",
    " \n",
    "y_train_pred = forest_final.predict(X_train)\n",
    "y_test_pred = forest_final.predict(X_test) \n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='forest_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "11a7fa5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 352,
       "width": 784
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = X_train.shape[1]\n",
    "features = [f'M-{cols-col}' for col in range(cols)]  \n",
    "data = forest_final.steps[1][1].feature_importances_.reshape(-1,1)\n",
    "imp = pd.DataFrame(data=data, index=features, columns=['Forest'])\n",
    "imp.plot(kind='bar'); # the most important months is the first previous three months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "80190bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Next_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subaru</th>\n",
       "      <td>273.765626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suzuki</th>\n",
       "      <td>246.159222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tata</th>\n",
       "      <td>0.035983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tazzari</th>\n",
       "      <td>0.035983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>238.629376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Think</th>\n",
       "      <td>0.035983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>1279.202421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>1980.871566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>754.306872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westfield</th>\n",
       "      <td>0.035983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Next_Sales\n",
       "Make                   \n",
       "Subaru       273.765626\n",
       "Suzuki       246.159222\n",
       "Tata           0.035983\n",
       "Tazzari        0.035983\n",
       "Tesla        238.629376\n",
       "Think          0.035983\n",
       "Toyota      1279.202421\n",
       "Volkswagen  1980.871566\n",
       "Volvo        754.306872\n",
       "Westfield      0.035983"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=0)\n",
    "\n",
    "forest_final = Pipeline([('scaler', MinMaxScaler()), ('ForestFinal', RandomForestRegressor(n_estimators=100, \n",
    "                                                                                           min_samples_split=5, \n",
    "                                                                                           min_samples_leaf=5, \n",
    "                                                                                           max_samples=0.5, \n",
    "                                                                                           max_features=0.4, \n",
    "                                                                                           max_depth=19, \n",
    "                                                                                           bootstrap=True))])\n",
    "\n",
    "forest_final.fit(X_train, y_train)\n",
    "\n",
    "forecast = pd.DataFrame(data=forest_final.predict(X_test), index=df.index, columns=['Next_Sales'])\n",
    "forecast.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbeaed2",
   "metadata": {},
   "source": [
    "## sklearn neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "a2d53b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 16971.36834111\n",
      "Validation score: 0.920519\n",
      "Iteration 2, loss = 5110.23720794\n",
      "Validation score: 0.931789\n",
      "Iteration 3, loss = 4565.24989091\n",
      "Validation score: 0.939719\n",
      "Iteration 4, loss = 3852.89505267\n",
      "Validation score: 0.947731\n",
      "Iteration 5, loss = 3449.10170482\n",
      "Validation score: 0.952096\n",
      "Iteration 6, loss = 3265.13428419\n",
      "Validation score: 0.953008\n",
      "Iteration 7, loss = 3209.02490989\n",
      "Validation score: 0.954035\n",
      "Iteration 8, loss = 3085.55584211\n",
      "Validation score: 0.951573\n",
      "Iteration 9, loss = 3064.69334411\n",
      "Validation score: 0.954850\n",
      "Iteration 10, loss = 3008.82441924\n",
      "Validation score: 0.953426\n",
      "Iteration 11, loss = 2999.89364823\n",
      "Validation score: 0.954806\n",
      "Iteration 12, loss = 2935.42363800\n",
      "Validation score: 0.950930\n",
      "Iteration 13, loss = 2945.29979431\n",
      "Validation score: 0.952048\n",
      "Iteration 14, loss = 2892.57673994\n",
      "Validation score: 0.954456\n",
      "Iteration 15, loss = 2898.20545926\n",
      "Validation score: 0.953670\n",
      "Iteration 16, loss = 2840.81105990\n",
      "Validation score: 0.956535\n",
      "Iteration 17, loss = 2853.17051733\n",
      "Validation score: 0.955087\n",
      "Iteration 18, loss = 2811.50052428\n",
      "Validation score: 0.954550\n",
      "Iteration 19, loss = 2859.53208914\n",
      "Validation score: 0.957451\n",
      "Iteration 20, loss = 2801.37358361\n",
      "Validation score: 0.956494\n",
      "Iteration 21, loss = 2826.67468237\n",
      "Validation score: 0.953650\n",
      "Iteration 22, loss = 2800.97152429\n",
      "Validation score: 0.957574\n",
      "Iteration 23, loss = 2774.53435708\n",
      "Validation score: 0.957465\n",
      "Iteration 24, loss = 2786.25617047\n",
      "Validation score: 0.957286\n",
      "Iteration 25, loss = 2759.36054757\n",
      "Validation score: 0.957647\n",
      "Iteration 26, loss = 2768.49175650\n",
      "Validation score: 0.956920\n",
      "Iteration 27, loss = 2775.32711925\n",
      "Validation score: 0.957906\n",
      "Iteration 28, loss = 2737.64666304\n",
      "Validation score: 0.957604\n",
      "Iteration 29, loss = 2740.10605118\n",
      "Validation score: 0.958141\n",
      "Iteration 30, loss = 2723.86415606\n",
      "Validation score: 0.957617\n",
      "Iteration 31, loss = 2734.11520275\n",
      "Validation score: 0.956248\n",
      "Iteration 32, loss = 2718.93903727\n",
      "Validation score: 0.957583\n",
      "Iteration 33, loss = 2708.15187273\n",
      "Validation score: 0.957827\n",
      "Iteration 34, loss = 2794.12130042\n",
      "Validation score: 0.956448\n",
      "Iteration 35, loss = 2717.14258181\n",
      "Validation score: 0.958125\n",
      "Iteration 36, loss = 2729.33100488\n",
      "Validation score: 0.956359\n",
      "Iteration 37, loss = 2807.90123038\n",
      "Validation score: 0.954742\n",
      "Iteration 38, loss = 2680.45248503\n",
      "Validation score: 0.954734\n",
      "Iteration 39, loss = 2678.08721670\n",
      "Validation score: 0.956289\n",
      "Iteration 40, loss = 2696.67853147\n",
      "Validation score: 0.958213\n",
      "Iteration 41, loss = 2660.16777892\n",
      "Validation score: 0.958391\n",
      "Iteration 42, loss = 2699.44483095\n",
      "Validation score: 0.957891\n",
      "Iteration 43, loss = 2671.49539269\n",
      "Validation score: 0.955042\n",
      "Iteration 44, loss = 2694.94566715\n",
      "Validation score: 0.958042\n",
      "Iteration 45, loss = 2657.01530109\n",
      "Validation score: 0.958134\n",
      "Iteration 46, loss = 2648.74621629\n",
      "Validation score: 0.957668\n",
      "Iteration 47, loss = 2637.09705193\n",
      "Validation score: 0.958059\n",
      "Iteration 48, loss = 2641.89330288\n",
      "Validation score: 0.958081\n",
      "Iteration 49, loss = 2639.54967327\n",
      "Validation score: 0.957831\n",
      "Iteration 50, loss = 2627.73160091\n",
      "Validation score: 0.953220\n",
      "Iteration 51, loss = 2623.89712487\n",
      "Validation score: 0.957034\n",
      "Iteration 52, loss = 2595.33693212\n",
      "Validation score: 0.957714\n",
      "Iteration 53, loss = 2590.92936057\n",
      "Validation score: 0.957525\n",
      "Iteration 54, loss = 2615.57414957\n",
      "Validation score: 0.956998\n",
      "Iteration 55, loss = 2628.97969433\n",
      "Validation score: 0.957136\n",
      "Iteration 56, loss = 2574.35117809\n",
      "Validation score: 0.955533\n",
      "Iteration 57, loss = 2598.76828229\n",
      "Validation score: 0.957352\n",
      "Iteration 58, loss = 2592.31860233\n",
      "Validation score: 0.957899\n",
      "Iteration 59, loss = 2629.03775109\n",
      "Validation score: 0.957108\n",
      "Iteration 60, loss = 2560.21381202\n",
      "Validation score: 0.957306\n",
      "Iteration 61, loss = 2572.66679465\n",
      "Validation score: 0.956254\n",
      "Iteration 62, loss = 2580.40615258\n",
      "Validation score: 0.957401\n",
      "Iteration 63, loss = 2561.93021908\n",
      "Validation score: 0.953763\n",
      "Iteration 64, loss = 2583.91167570\n",
      "Validation score: 0.957855\n",
      "Iteration 65, loss = 2577.15733048\n",
      "Validation score: 0.954738\n",
      "Iteration 66, loss = 2560.55920948\n",
      "Validation score: 0.956368\n",
      "Iteration 67, loss = 2582.89620406\n",
      "Validation score: 0.953563\n",
      "Iteration 68, loss = 2539.67821685\n",
      "Validation score: 0.954502\n",
      "Iteration 69, loss = 2586.50281436\n",
      "Validation score: 0.958076\n",
      "Iteration 70, loss = 2539.07454030\n",
      "Validation score: 0.957650\n",
      "Iteration 71, loss = 2539.17665727\n",
      "Validation score: 0.957874\n",
      "Iteration 72, loss = 2526.09039548\n",
      "Validation score: 0.955149\n",
      "Iteration 73, loss = 2578.01193607\n",
      "Validation score: 0.958080\n",
      "Iteration 74, loss = 2568.79862623\n",
      "Validation score: 0.957712\n",
      "Iteration 75, loss = 2552.06760454\n",
      "Validation score: 0.956531\n",
      "Iteration 76, loss = 2560.13477279\n",
      "Validation score: 0.955206\n",
      "Iteration 77, loss = 2482.22410817\n",
      "Validation score: 0.957790\n",
      "Iteration 78, loss = 2485.20904692\n",
      "Validation score: 0.955304\n",
      "Iteration 79, loss = 2482.92618286\n",
      "Validation score: 0.957447\n",
      "Iteration 80, loss = 2494.84606321\n",
      "Validation score: 0.955910\n",
      "Iteration 81, loss = 2508.87559548\n",
      "Validation score: 0.957711\n",
      "Iteration 82, loss = 2525.15199528\n",
      "Validation score: 0.957607\n",
      "Iteration 83, loss = 2485.24101376\n",
      "Validation score: 0.958265\n",
      "Iteration 84, loss = 2475.47789266\n",
      "Validation score: 0.957764\n",
      "Iteration 85, loss = 2464.08604742\n",
      "Validation score: 0.957631\n",
      "Iteration 86, loss = 2477.27369603\n",
      "Validation score: 0.957531\n",
      "Iteration 87, loss = 2472.67163458\n",
      "Validation score: 0.957814\n",
      "Iteration 88, loss = 2541.88006435\n",
      "Validation score: 0.953028\n",
      "Iteration 89, loss = 2455.09286815\n",
      "Validation score: 0.956354\n",
      "Iteration 90, loss = 2451.18673487\n",
      "Validation score: 0.958016\n",
      "Iteration 91, loss = 2473.74032244\n",
      "Validation score: 0.955968\n",
      "Iteration 92, loss = 2470.03417351\n",
      "Validation score: 0.957904\n",
      "Validation score did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "         MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "NN                                                    \n",
      "Train  29.25  71.99 -0.83    17.37     42.77      0.95\n",
      "Test   35.83  87.70  0.56    17.84     43.66      0.95\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "param_fixed = {'NN__activation': 'relu', \n",
    "               'NN__solver': 'adam', \n",
    "               'NN__early_stopping': True, \n",
    "               'NN__n_iter_no_change': 50, \n",
    "               'NN__validation_fraction': .1, \n",
    "               'NN__tol': .0001}\n",
    "\n",
    "NN_b = Pipeline([('scaler', MinMaxScaler()), \n",
    "                 ('NN', MLPRegressor(hidden_layer_sizes=(20, 20), **param_fixed, verbose=True))])\n",
    "\n",
    "NN_b.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = NN_b.predict(X_train) \n",
    "y_test_pred = NN_b.predict(X_test)\n",
    "\n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='NN_b')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f230c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n",
      "Tuned NN Parameters: {'learning_rate_init': 0.005, 'hidden_layer_sizes': [30, 30, 30, 30, 30], 'beta_2': 0.995, 'beta_1': 0.975, 'alpha': 0.001}\n",
      "\n",
      "                MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "NN optimized                                                 \n",
      "Train         28.55  69.02 -3.51    16.96     41.00      0.96\n",
      "Test          34.66  86.15 -1.91    17.25     42.89      0.95\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=12)\n",
    "\n",
    "NN = Pipeline([('scaler', MinMaxScaler()), \n",
    "               ('NN', MLPRegressor(activation='relu', \n",
    "                                   solver='adam', \n",
    "                                   early_stopping=True, \n",
    "                                   n_iter_no_change=50, \n",
    "                                   validation_fraction=.1, \n",
    "                                   tol=.0001))])\n",
    "\n",
    "param_dist = {'NN__hidden_layer_sizes': [[neuron]*hidden_layer for neuron in range(10,60,10) for hidden_layer in range(2,7)], \n",
    "              'NN__alpha': [5, 1, .5, .1, .05, .01, .001], \n",
    "              'NN__learning_rate_init': [.05, .01, .005, .001, .0005], \n",
    "              'NN__beta_1': [.85, .875, .9, .95, .975, .99, .995], \n",
    "              'NN__beta_2': [.99, .995, .999, .9995, .9999]}\n",
    "\n",
    "NN_cv = RandomizedSearchCV(NN, param_dist, cv=10, verbose=2, n_jobs=-1, n_iter=200, scoring='neg_mean_absolute_error')\n",
    "NN_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Tuned NN Parameters:', NN_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "87d49ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            MAE   RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "NN Final                                                 \n",
      "Train     29.25  72.58 -1.45    17.93     44.49      0.95\n",
      "Test      32.10  82.84 -1.93    17.04     43.97      0.95\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=20)\n",
    "\n",
    "NN_final = Pipeline([('scaler', MinMaxScaler()), \n",
    "                     ('NN', MLPRegressor(activation='relu', \n",
    "                                         solver='adam', \n",
    "                                         early_stopping=True, \n",
    "                                         n_iter_no_change=50, \n",
    "                                         validation_fraction=.1, \n",
    "                                         tol=.0001, \n",
    "                                         hidden_layer_sizes=[30, 30, 30, 30, 30], \n",
    "                                         alpha=.001, \n",
    "                                         learning_rate_init=.005, \n",
    "                                         beta_1=.97, \n",
    "                                         beta_2=.995))])\n",
    "NN_final.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = NN_final.predict(X_train) \n",
    "y_test_pred = NN_final.predict(X_test)\n",
    "\n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='NN Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "2852b0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Next_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subaru</th>\n",
       "      <td>237.845909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suzuki</th>\n",
       "      <td>268.173489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tata</th>\n",
       "      <td>0.988654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tazzari</th>\n",
       "      <td>0.988654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tesla</th>\n",
       "      <td>176.352180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Think</th>\n",
       "      <td>0.988654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toyota</th>\n",
       "      <td>1151.028659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen</th>\n",
       "      <td>1850.869401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo</th>\n",
       "      <td>744.645220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Westfield</th>\n",
       "      <td>0.988654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Next_Sales\n",
       "Make                   \n",
       "Subaru       237.845909\n",
       "Suzuki       268.173489\n",
       "Tata           0.988654\n",
       "Tazzari        0.988654\n",
       "Tesla        176.352180\n",
       "Think          0.988654\n",
       "Toyota      1151.028659\n",
       "Volkswagen  1850.869401\n",
       "Volvo        744.645220\n",
       "Westfield      0.988654"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forecasting\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=12, y_len=1, test_loops=0)\n",
    "\n",
    "NN_final = Pipeline([('scaler', MinMaxScaler()), \n",
    "                     ('NN', MLPRegressor(activation='relu', \n",
    "                                         solver='adam', \n",
    "                                         early_stopping=True, \n",
    "                                         n_iter_no_change=50, \n",
    "                                         validation_fraction=.1, \n",
    "                                         tol=.0001, \n",
    "                                         hidden_layer_sizes=[30, 30, 30, 30, 30], \n",
    "                                         alpha=.001, \n",
    "                                         learning_rate_init=.005, \n",
    "                                         beta_1=.97, \n",
    "                                         beta_2=.995))])\n",
    "NN_final.fit(X_train, y_train)\n",
    "\n",
    "forecast = pd.DataFrame(data=NN_final.predict(X_test), index=df.index, columns=['Next_Sales'])\n",
    "forecast.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7602d64b",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "40c86775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5720, 3, 1), (1170, 3, 1), (5720, 1), (1170, 1))"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=3, y_len=1, test_loops=12)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "n_steps = 3 # =x_len\n",
    "n_features = 1\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "5f044679",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=60, \n",
    "                                                           kernel_size=5, \n",
    "                                                           strides=1, \n",
    "                                                           padding=\"causal\", \n",
    "                                                           activation=\"relu\", \n",
    "                                                           input_shape=(n_steps, n_features)), \n",
    "                                    tf.keras.layers.LSTM(60, return_sequences=True), \n",
    "                                    tf.keras.layers.LSTM(60), tf.keras.layers.Dense(1), \n",
    "                                    tf.keras.layers.Lambda(lambda x: x * 400)])\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100 ,batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "c89bc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         MAE    RMSE  Bias  MAE_pct  RMSE_pct  r2_score\n",
      "LSTM                                                   \n",
      "Train  30.29   77.26 -1.80    18.53     47.26      0.94\n",
      "Test   38.94  106.53  2.26    20.54     56.19      0.92\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train) \n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "kpi(y_train, y_train_pred, y_test, y_test_pred, name='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "1b286de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting\n",
    "\n",
    "X_train, y_train, X_test, y_test = train_test_datasets(df, x_len=3, y_len=1, test_loops=0)\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "n_steps = 3 # =x_len\n",
    "n_features = 1\n",
    "\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], n_features))\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "b4b5a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "model1 = tf.keras.models.Sequential([tf.keras.layers.Conv1D(filters=60, \n",
    "                                                           kernel_size=5, \n",
    "                                                           strides=1, \n",
    "                                                           padding=\"causal\", \n",
    "                                                           activation=\"relu\", \n",
    "                                                           input_shape=(n_steps, n_features)), \n",
    "                                    tf.keras.layers.LSTM(60, return_sequences=True), \n",
    "                                    tf.keras.layers.LSTM(60), tf.keras.layers.Dense(1), \n",
    "                                    tf.keras.layers.Lambda(lambda x: x * 400)])\n",
    "\n",
    "\n",
    "model1.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "history = model1.fit(X_train, y_train, epochs=100 ,batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "cf203ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Next_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alfa Romeo</th>\n",
       "      <td>2.751791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aston Martin</th>\n",
       "      <td>2.552545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi</th>\n",
       "      <td>507.842651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>999.981812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bentley</th>\n",
       "      <td>2.552545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Next_Sales\n",
       "Make                    \n",
       "Alfa Romeo      2.751791\n",
       "Aston Martin    2.552545\n",
       "Audi          507.842651\n",
       "BMW           999.981812\n",
       "Bentley         2.552545"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast = pd.DataFrame(data=model1.predict(X_test), index=df.index, columns=['Next_Sales'])\n",
    "forecast.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
